{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import auto_feature\n",
    "#dreload(auto_feature)\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import linear_model\n",
    "from sklearn.base import clone\n",
    "boston = load_boston()\n",
    "#print(boston.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_address = \"../Datasets/\"\n",
    "dataSets = []\n",
    "dataSets_temp = []\n",
    "data_names = ['servo','abalone','ozone']\n",
    "for i in range(0,len(data_names)):\n",
    "    dataSets_temp.append(pd.read_csv(base_address+data_names[i]+'.csv'))\n",
    "    temp_data = pd.read_csv(base_address+data_names[i]+'.csv')\n",
    "    temp_data = pd.get_dummies(temp_data)\n",
    "    temp_output = pd.DataFrame(temp_data['output'])\n",
    "    temp_data.drop('output',axis=1,inplace=True)\n",
    "    temp_data = pd.concat([temp_data, temp_output], axis=1)\n",
    "    dataSets.append(temp_data)\n",
    "# Boston Data\n",
    "b_feat = pd.DataFrame(boston.data)\n",
    "b_feat.columns = ['feat_0','feat_1','feat_2','feat_3','feat_4','feat_5','feat_6','feat_7','feat_8','feat_9','feat_10','feat_11','feat_12']\n",
    "b_target = pd.DataFrame(boston.target)\n",
    "b_target.columns = ['output']\n",
    "b_data = pd.concat([b_feat,b_target],axis=1)\n",
    "dataSets.append(b_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_result(model_,data_, frac):\n",
    "    model = clone(model_)\n",
    "    output = data_['output']\n",
    "    data_.drop('output',axis=1,inplace=True)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_, output, test_size=frac)\n",
    "    model.fit(X_train,y_train)\n",
    "    test_result = model.predict(X_test)\n",
    "    return mean_squared_error(y_test,test_result), test_result, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_result_iter(data, N_iterations, frac, models):\n",
    "    #get_result(FS,temp_data)\n",
    "    model_list = []\n",
    "    Result_mses = []\n",
    "    for i in range(0,len(models)):\n",
    "        model_iter_results = []\n",
    "        for j in range(0,N_iterations):\n",
    "            temp_data = data.copy(deep=True)\n",
    "            temp_rs, temp_pred, model = get_result(models[i],temp_data, frac)\n",
    "            #print model.best_params_\n",
    "            model_iter_results.append(temp_rs)\n",
    "            model_list.append(model)\n",
    "        Result_mses.append(sum(model_iter_results)/len(model_iter_results))\n",
    "    return Result_mses, model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    8.2s\n",
      "[Parallel(n_jobs=1)]: Done  50 jobs       | elapsed:  8.0min\n",
      "[Parallel(n_jobs=1)]: Done 200 jobs       | elapsed: 89.8min\n",
      "[Parallel(n_jobs=1)]: Done 216 out of 216 | elapsed: 105.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "{'indpb': 0.1, 'N_individual': 5, 'test_frac': 0.80000000000000004}\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    8.7s\n",
      "[Parallel(n_jobs=1)]: Done  50 jobs       | elapsed:  8.3min\n",
      "[Parallel(n_jobs=1)]: Done 200 jobs       | elapsed: 89.4min\n",
      "[Parallel(n_jobs=1)]: Done 216 out of 216 | elapsed: 107.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'indpb': 0.30000000000000004, 'N_individual': 10, 'test_frac': 0.80000000000000004}\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    9.8s\n",
      "[Parallel(n_jobs=1)]: Done  50 jobs       | elapsed:  8.9min\n",
      "[Parallel(n_jobs=1)]: Done 200 jobs       | elapsed: 252.3min\n",
      "[Parallel(n_jobs=1)]: Done 216 out of 216 | elapsed: 265.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'indpb': 0.1, 'N_individual': 5, 'test_frac': 0.80000000000000004}\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    8.1s\n",
      "[Parallel(n_jobs=1)]: Done  50 jobs       | elapsed:  8.2min\n",
      "[Parallel(n_jobs=1)]: Done 200 jobs       | elapsed: 83.9min\n",
      "[Parallel(n_jobs=1)]: Done 216 out of 216 | elapsed: 97.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'indpb': 0.5000000000000001, 'N_individual': 5, 'test_frac': 0.80000000000000004}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Stacker-CV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Servo</th>\n",
       "      <td>3.344036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abalone</th>\n",
       "      <td>5.342386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ozone</th>\n",
       "      <td>22.739452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Boston-housing</th>\n",
       "      <td>26.387494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Feature Stacker-CV\n",
       "Servo                     3.344036\n",
       "Abalone                   5.342386\n",
       "Ozone                    22.739452\n",
       "Boston-housing           26.387494"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Res_all_ds = []\n",
    "model_f = []\n",
    "for i in range(0,len(dataSets)):\n",
    "    t_data = dataSets[i].copy(deep=True)\n",
    "    N_iterations = 1\n",
    "    g_frac = 0.10\n",
    "    #parameters = {'indpb':np.arange(0.1,0.6,0.2).tolist(), 'mutpb':np.arange(0.1,0.7,0.2).tolist(),\n",
    "                  #'cxpb':np.arange(0.1,0.7,0.2).tolist(),'N_individual':np.arange(4,15,2).tolist(),\n",
    "                  #'test_frac':np.arange(0.1,1,0.2)}\n",
    "    parameters = {'indpb':np.arange(0.1,0.6,0.2).tolist(),'N_individual':[5,10,20,25,35,50],\n",
    "                  'test_frac':np.arange(0.2,1,0.2)}\n",
    "    FS = auto_feature.Feature_Stacker(ngen=20,cxpb = 0.6, mutpb = 0.4)\n",
    "    #grid_model = RandomizedSearchCV(FS, parameters, verbose=True, scoring=\"mean_squared_error\",n_iter=100)\n",
    "    grid_model = GridSearchCV(FS, parameters, verbose=True, scoring=\"mean_squared_error\")\n",
    "    g_models = []\n",
    "    g_models.append(grid_model)\n",
    "    #g_models.append(linear_model.LinearRegression())\n",
    "    #g_models.append(linear_model.LassoCV(n_alphas=100))\n",
    "    Result_t, model_list = get_result_iter(t_data, N_iterations, g_frac, g_models)\n",
    "    Res_all_ds.append(Result_t)\n",
    "    model_f.append(model_list)\n",
    "dataSet_names = ['Servo','Abalone','Ozone','Boston-housing']\n",
    "model_names = ['Feature Stacker-CV']\n",
    "Result_test_bench = pd.DataFrame(Res_all_ds)\n",
    "Result_test_bench.columns = model_names\n",
    "Result_test_bench.set_index([dataSet_names],inplace=True)\n",
    "Result_test_bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Result_test_bench.set_index([dataSet_names],inplace=True)\n",
    "Result_test_bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test_frac = 1, n =5\n",
    "Result_test_bench_bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test_frac = 0.5, n =25\n",
    "Result_test_bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test_frac = 1, n =25\n",
    "Result_test_bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(dataSets)):\n",
    "    print dataSets[i].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataSet_names = ['Servo','Abalone','Ozone','Boston-housing']\n",
    "model_names = ['Feature Stacker', 'Linear Regression']\n",
    "Result_test_bench = pd.DataFrame(Res_all_ds)\n",
    "Result_test_bench.columns = model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod_FS_GT_1 = model_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod_0_s = pickle.dumps(model_f[0][0])\n",
    "mod_1_s = pickle.dumps(model_f[1][0])\n",
    "mod_2_s = pickle.dumps(model_f[2][0])\n",
    "mod_3_s = pickle.dumps(model_f[3][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joblib.dump(model_f[0][0], 'model-0.pkl')\n",
    "joblib.dump(model_f[1][0], 'model-1.pkl')\n",
    "joblib.dump(model_f[2][0], 'model-2.pkl')\n",
    "joblib.dump(model_f[3][0], 'model-3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "30\n",
      "50\n",
      "70\n",
      "90\n",
      "110\n",
      "130\n",
      "150\n",
      "170\n",
      "190\n",
      "210\n",
      "230\n",
      "250\n",
      "270\n",
      "290\n",
      "310\n",
      "330\n",
      "350\n",
      "370\n",
      "390\n",
      "410\n",
      "430\n",
      "450\n",
      "470\n",
      "490\n",
      "510\n",
      "530\n",
      "550\n",
      "570\n",
      "590\n",
      "610\n",
      "630\n",
      "650\n",
      "670\n",
      "690\n"
     ]
    }
   ],
   "source": [
    "# Trying it on server\n",
    "plot_res = []\n",
    "for i in range(10,700,20):\n",
    "    print i\n",
    "    t_data_check = dataSets[0].copy(deep=True)\n",
    "    N_iterations = 10\n",
    "    g_frac = 0.10\n",
    "    g_servo = []\n",
    "    FS1 = auto_feature.Feature_Stacker(ngen=i,cxpb = 0.6, mutpb = 0.4, indpb= 0.1, N_individual=5, test_frac=0.80000000000000004)\n",
    "    g_servo.append(FS1)\n",
    "    Result_servo, model_list_servo = get_result_iter(t_data_check, N_iterations, g_frac, g_servo)\n",
    "    plot_res.append(Result_servo[0])\n",
    "    Result_servo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4980921370534261"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Result_servo[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
