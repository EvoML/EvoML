{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import auto_feature\n",
    "#dreload(auto_feature)\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import linear_model\n",
    "from sklearn.base import clone\n",
    "boston = load_boston()\n",
    "#print(boston.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_address = \"../Datasets/\"\n",
    "dataSets = []\n",
    "dataSets_temp = []\n",
    "data_names = ['servo','abalone','ozone']\n",
    "for i in range(0,len(data_names)):\n",
    "    dataSets_temp.append(pd.read_csv(base_address+data_names[i]+'.csv'))\n",
    "    temp_data = pd.read_csv(base_address+data_names[i]+'.csv')\n",
    "    temp_data = pd.get_dummies(temp_data)\n",
    "    temp_output = pd.DataFrame(temp_data['output'])\n",
    "    temp_data.drop('output',axis=1,inplace=True)\n",
    "    temp_data = pd.concat([temp_data, temp_output], axis=1)\n",
    "    dataSets.append(temp_data)\n",
    "# Boston Data\n",
    "b_feat = pd.DataFrame(boston.data)\n",
    "b_feat.columns = ['feat_0','feat_1','feat_2','feat_3','feat_4','feat_5','feat_6','feat_7','feat_8','feat_9','feat_10','feat_11','feat_12']\n",
    "b_target = pd.DataFrame(boston.target)\n",
    "b_target.columns = ['output']\n",
    "b_data = pd.concat([b_feat,b_target],axis=1)\n",
    "dataSets.append(b_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_result(model_,data_, frac):\n",
    "    model = clone(model_)\n",
    "    output = data_['output']\n",
    "    data_.drop('output',axis=1,inplace=True)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_, output, test_size=frac)\n",
    "    model.fit(X_train,y_train)\n",
    "    test_result = model.predict(X_test)\n",
    "    return mean_squared_error(y_test,test_result), test_result, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_result_iter(data, N_iterations, frac, models):\n",
    "    #get_result(FS,temp_data)\n",
    "    model_list = []\n",
    "    Result_mses = []\n",
    "    for i in range(0,len(models)):\n",
    "        model_iter_results = []\n",
    "        for j in range(0,N_iterations):\n",
    "            temp_data = data.copy(deep=True)\n",
    "            temp_rs, temp_pred, model = get_result(models[i],temp_data, frac)\n",
    "            print model.best_params_\n",
    "            model_iter_results.append(temp_rs)\n",
    "            model_list.append(model)\n",
    "        Result_mses.append(sum(model_iter_results)/len(model_iter_results))\n",
    "    return Result_mses, model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Res_all_ds = []\n",
    "model_f = []\n",
    "for i in range(0,len(dataSets)):\n",
    "    t_data = dataSets[i].copy(deep=True)\n",
    "    N_iterations = 1\n",
    "    g_frac = 0.10\n",
    "    #parameters = {'indpb':np.arange(0.1,0.6,0.2).tolist(),'N_individual':[5,10,20,25,35,50],\n",
    "    #              'test_frac':np.arange(0.2,1,0.2)}\n",
    "    #FS = auto_feature.Feature_Stacker(ngen=20,cxpb = 0.6, mutpb = 0.4)\n",
    "    #grid_model = RandomizedSearchCV(FS, parameters, verbose=True, scoring=\"mean_squared_error\",n_iter=100)\n",
    "    #grid_model = GridSearchCV(FS, parameters, verbose=True, scoring=\"mean_squared_error\")\n",
    "    g_models = []\n",
    "    \n",
    "    #g_models.append(grid_model)\n",
    "    #g_models.append(linear_model.LinearRegression())\n",
    "    #g_models.append(linear_model.LassoCV(n_alphas=100))\n",
    "    Result_t, model_list = get_result_iter(t_data, N_iterations, g_frac, g_models)\n",
    "    Res_all_ds.append(Result_t)\n",
    "    model_f.append(model_list)\n",
    "dataSet_names = ['Servo','Abalone','Ozone','Boston-housing']\n",
    "model_names = ['Feature Stacker-CV']\n",
    "Result_test_bench = pd.DataFrame(Res_all_ds)\n",
    "Result_test_bench.columns = model_names\n",
    "Result_test_bench.set_index([dataSet_names],inplace=True)\n",
    "Result_test_bench"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
